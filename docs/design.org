* Brainstorming 2017

- Run Class
  - point to a directory contains run data, it load the data
    - needs to be a run -directory (not experiment)
  - r = Run(datapath)
  - r.set_default_instrument("DET/AGPIPD0-M")
  - implementation
    - scan directotry for files
    - open all to understand which trainIDs and pulses are there
    - if 16 files, check all train ID are the same

- Terminology
  - train IDs (absolute) -> trainID
  - pulse IDs
  - relative train IDs (starting from 0 in each run) -> t (=relative Train

  - r.index(trainID, pulseID) -> index
  - r.index(t, pulseID) -> index

  - r.data(t = 1, pulse = 3)
  - r.data(trainID = 14434365, pulse = 3)

  - r.data(index=16)
  - r.data(index=range(0, 400, 2))
  - r.data(device="DET/AGIPD0-M") or   - data(instrument="DET/AGIPD0-M")
  -

- other functions / accessible from command line tool
  - dump_indices  | index | trainID | pulse ID |
  - size -> len(index), len(trainID), len(pulseID) or maybe
  - size_trains() ->
  - size_pulses () ->
  - size_index () ->

  - file(trainId) -> list of files that contains the data

* Brainstorming (Jan) 2018

Pipeline:

h5tool inputdataname -> train, pulse, source name to reduce data ->
calibration -> analysis -> filter -> calibration -> conversion -> output

- can read and combine data from multiple files
  - reconstruct trains from a run and
  - stream (iterate over) them in the correct order

- initial exploration:
  - how many trains
  - what detector data (fast data), -> names of sources
    - how many pulses
  - what sensors (slow data) -> names of sources
  - overview
  - show realtime for run: when was the run started (date and time),
    for how long did the measurement go?

- conversion of data into other formats
  - numpy array (detector data)
  - plain txt
  - matlab matrix (*.mat)
  - png
  - cheetah
  - dump summary to screen
  - xfel hdf5 files
  - cxi
  - python dictionaries / json / ...
  - csv (slow data)
  - stream it over 0MQ (or similar)

- selection of trains, pulses and sources
  - reduce the data we work on

- analysis of pulses/trains
  - for example total photon count (if calibrated)
  - assemble detector modules in roughly right geometry
  - integration over region of interest

- filters
  - use results of this analysis as a filter

Additional features:

- loop over directory of runs to show summary table for each
  - name, #trains, date and time & duration, detector, if scan ->
    scanning parameters/device

  (Could just be a bash loop, something like:

  for dir in *; do
     h5tool --info -verbose $dir
  done
