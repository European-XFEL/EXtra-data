{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing LPD data\n",
    "\n",
    "The Large Pixel Detector (LPD) is made of 16 modules which record data separately.\n",
    "`extra_data` includes convenient interfaces to access this data together.\n",
    "\n",
    "This example stands by itself, but if you need more generic access to the data,\n",
    "please see other examples, including [Reading data to analyse in memory](xpd_examples.ipynb)\n",
    "and [Reading data train by train](iterate_trains.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example uses some empty sample files which are generated by this cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Written examples.\r\n"
     ]
    }
   ],
   "source": [
    "!python3 -m extra_data.tests.make_examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's load a run containing LPD data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "frozenset({'FXE_DET_LPD1M-1/DET/0CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/10CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/11CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/12CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/13CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/14CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/15CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/1CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/2CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/3CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/4CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/5CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/6CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/7CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/8CH0:xtdf',\n",
       "           'FXE_DET_LPD1M-1/DET/9CH0:xtdf',\n",
       "           'FXE_XAD_GEC/CAM/CAMERA:daqOutput',\n",
       "           'FXE_XAD_GEC/CAM/CAMERA_NODATA:daqOutput',\n",
       "           'SA1_XTD2_XGM/DOOCS/MAIN:output',\n",
       "           'SPB_XTD9_XGM/DOOCS/MAIN:output'})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extra_data import RunDirectory, by_index\n",
    "\n",
    "run = RunDirectory('fxe_example_run/')\n",
    "# Using only the first three trains to keep this example light:\n",
    "run = run.select_trains(by_index[:3])\n",
    "\n",
    "run.instrument_sources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normal access methods give us each module separately:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384, 1, 256, 256)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_module0 = run['FXE_DET_LPD1M-1/DET/0CH0:xtdf', 'image.data'].ndarray()\n",
    "data_module0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class `extra_data.components.LPD1M` can piece these together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<LPD1M: Data interface for detector 'FXE_DET_LPD1M-1' with 16 modules>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from extra_data.components import LPD1M\n",
    "lpd = LPD1M(run)\n",
    "lpd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (16, 3, 128, 256, 256)\n",
      "Dimensions: ('module', 'train', 'pulse', 'slow_scan', 'fast_scan')\n"
     ]
    }
   ],
   "source": [
    "image_data = lpd.get_array('image.data')\n",
    "print(\"Data shape:\", image_data.shape)\n",
    "print(\"Dimensions:\", image_data.dims)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** This class pulls the data together, but it doesn't know how the modules are physically arranged,\n",
    "so it can't produce a detector image. Other examples show how to use detector geometry to produce images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select only certain modules of the detector. For example, modules 2 (Q1M3), 7 (Q2M4), 8 (Q3M1) and 13 (Q4M2) are the four modules around the center of the detector:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (4, 3, 128, 256, 256)\n",
      "Dimensions: ('module', 'train', 'pulse', 'slow_scan', 'fast_scan')\n",
      "\n",
      "Data for one pulse:\n",
      "<xarray.DataArray (module: 4, slow_scan: 256, fast_scan: 256)>\n",
      "array([[[0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0],\n",
      "        ...,\n",
      "        [0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0]],\n",
      "\n",
      "       [[0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0],\n",
      "        ...,\n",
      "        [0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0]],\n",
      "\n",
      "       [[0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0],\n",
      "        ...,\n",
      "        [0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0]],\n",
      "\n",
      "       [[0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0],\n",
      "        ...,\n",
      "        [0, 0, ..., 0, 0],\n",
      "        [0, 0, ..., 0, 0]]], dtype=uint16)\n",
      "Coordinates:\n",
      "    pulse    uint64 0\n",
      "    train    uint64 10000\n",
      "  * module   (module) int64 2 7 8 13\n",
      "Dimensions without coordinates: slow_scan, fast_scan\n"
     ]
    }
   ],
   "source": [
    "lpd = LPD1M(run, modules=[2, 7, 8, 13])\n",
    "image_data = lpd.get_array('image.data')\n",
    "print(\"Data shape:\", image_data.shape)\n",
    "print(\"Dimensions:\", image_data.dims)\n",
    "\n",
    "print()\n",
    "print(\"Data for one pulse:\")\n",
    "print(image_data.sel(train=10000, pulse=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned array is an *xarray* object with labelled axes.\n",
    "See [Indexing and selecting data](http://xarray.pydata.org/en/stable/indexing.html) in the xarray docs\n",
    "for more on what you can do with it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This interface also supports iterating train-by-train through detector data, giving labelled arrays again:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train 10000\n",
      "Keys in data: ['detector.data', 'detector.trainId', 'header.dataId', 'header.linkId', 'header.magicNumberBegin', 'header.majorTrainFormatVersion', 'header.minorTrainFormatVersion', 'header.pulseCount', 'header.reserved', 'header.trainId', 'image.cellId', 'image.data', 'image.length', 'image.pulseId', 'image.status', 'image.trainId', 'trailer.checksum', 'trailer.magicNumberEnd', 'trailer.status', 'trailer.trainId']\n",
      "Image data shape: (4, 1, 16, 256, 256)\n",
      "\n",
      "Train 10001\n",
      "Keys in data: ['detector.data', 'detector.trainId', 'header.dataId', 'header.linkId', 'header.magicNumberBegin', 'header.majorTrainFormatVersion', 'header.minorTrainFormatVersion', 'header.pulseCount', 'header.reserved', 'header.trainId', 'image.cellId', 'image.data', 'image.length', 'image.pulseId', 'image.status', 'image.trainId', 'trailer.checksum', 'trailer.magicNumberEnd', 'trailer.status', 'trailer.trainId']\n",
      "Image data shape: (4, 1, 16, 256, 256)\n",
      "\n",
      "Train 10002\n",
      "Keys in data: ['detector.data', 'detector.trainId', 'header.dataId', 'header.linkId', 'header.magicNumberBegin', 'header.majorTrainFormatVersion', 'header.minorTrainFormatVersion', 'header.pulseCount', 'header.reserved', 'header.trainId', 'image.cellId', 'image.data', 'image.length', 'image.pulseId', 'image.status', 'image.trainId', 'trailer.checksum', 'trailer.magicNumberEnd', 'trailer.status', 'trailer.trainId']\n",
      "Image data shape: (4, 1, 16, 256, 256)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for tid, train_data in lpd.trains(pulses=by_index[:16]):\n",
    "    print(\"Train\", tid)\n",
    "    print(\"Keys in data:\", sorted(train_data.keys()))\n",
    "    print(\"Image data shape:\", train_data['image.data'].shape)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LPD data may also be recorded in *parallel gain* mode, resulting in high-, medium- and low-gain frames for each pulse. To read this kind of data with the correct labels, use `LPD1M(run, parallel_gain=True)`. This will retrieve data with an extra gain dimension, labelled with 0, 1 and 2 for high-, medium- and low-gain respectively."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xfel",
   "language": "python",
   "name": "xfel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
